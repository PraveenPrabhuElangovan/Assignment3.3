Hadoop 2.x: HDFS: a)Master daemon:Name mode: Namenode is the master node in the hadoop framwoek. It plays a very pivotal role in determining how the input data will be distributed among various other notes. It holds the metadata not the actual data.it determines the number of data nods in which the actual data will be distributed. It has a parallel communication with job processing module which is control by the job tracker.job tracker in turn has direct communication channel wih task tracker which sends periodic heart beats back to the job tracker.
b)Secondary name node : It does CPU intensive tasks for Namenode. In more details, it combines the Edit log and fs_image and returns the consolidated file to Namenode. Namenode then loads that file into RAM. But, secondary namenode doesn't provide failover capabilities.  So, in case of Namenode failure, Hadoop admins have to manually recover the data from Secondary Namenode.
c)Slave Daemon:Datanode : A DataNode stores data in the [HadoopFileSystem]. A functional filesystem has more than one DataNode, with data replicated across them.
On startup, a DataNode connects to the NameNode; spinning until that service comes up. It then responds to requests from the NameNode for filesystem operations.

MapReduce: a)Master Daemon:Resource manager :  RESOURCE MANAGER(master daemon-1 IN NUMBER) 1.schedule task across node resource manager get the job and then assign it to each node Yarn schedules the job using 3 scheduler 1.FIFO(first in first out) 2.capacity scheduler 3.fair scheduler 1.FIFO The first job which comes to cluster get completed first but is rarely used as it may result in waiting of jobs 2.capacity scheduler Here the resource are allocated in que. fair scheduler here the resourced among the resources proportionately so none of job waits. By default capacity scheduler is used
b)Slave Daemon:Node Manager: On startup, this component registers with the RM and sends information about the resources available on the nodes. Subsequent NM-RM communication is to provide updates on container statuses â€“ new containers running on the node, completed containers, etc.
